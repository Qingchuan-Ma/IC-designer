# 模型压缩技术间的关系

  各种压缩算法的目的都相同，即使模型能够成功部署到移动端、嵌入式设备或者人工智能FPGA芯片上。在使用时，模型剪枝、量化、低秩分解和知识蒸馏都能同时应用到卷积层和全连接层上。

  量化和剪枝都会去掉对模型表现影响不大的冗余参数。他们对不同设置都具有鲁棒性，可以获得较好模型准确度，既支持从头训练也支持用原模型权值初始化后训练。

  知识蒸馏是使用原模型作为教师网络，训练出一个同样能完成任务但更小的学生网络。知识蒸馏所得模型的表现较多地受应用和网络结构影响。另外，知识蒸馏只能从头开始训练，也就是说，学生网络不能用教师网络的权值初始化。

  这些模型压缩技术独立设计，联合使用可相得益彰。剪枝对网络结构进行调整，量化对数据位宽进行调整，这两个技术可以作用于同一个网络，使得该网络既在结构上更紧凑，又能降低数据位宽，但剪枝量化无可避免地会使模型表现下降，那么就可以利用知识蒸馏对模型表现的恢复能力，让小模型作为学生网络，接受原模型的训练，使小模型达到原模型的准确度。

